{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/talipov/MyProjects/projectX/acosta_env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\n",
    "    shape=[batch_size, 50, 64],\n",
    "    dtype=tf.float32\n",
    ")\n",
    "y = tf.placeholder(\n",
    "    shape=[batch_size, 1],\n",
    "    dtype=tf.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fw_lstm_cell_1 = tf.contrib.rnn.LSTMCell(\n",
    "    num_units=128, \n",
    ")\n",
    "fw_lstm_cell_2 = tf.contrib.rnn.LSTMCell(\n",
    "    num_units=128, \n",
    ")\n",
    "bw_lstm_cell_1 = tf.contrib.rnn.LSTMCell(\n",
    "    num_units=128, \n",
    ")\n",
    "bw_lstm_cell_2 = tf.contrib.rnn.LSTMCell(\n",
    "    num_units=128, \n",
    ")\n",
    "outputs, final_fw, final_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
    "    [fw_lstm_cell_1],#,fw_lstm_cell_2],\n",
    "    [bw_lstm_cell_1],#,bw_lstm_cell_2],\n",
    "    x,\n",
    "    dtype=tf.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_fw =  tf.concat( [final_fw[0][0],final_fw[0][1]],axis=1)\n",
    "final_bw =  tf.concat( [final_bw[0][0],final_bw[0][1]],axis=1)\n",
    "final = tf.concat( [final_fw, final_bw], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = tf.layers.Dense(units=128, activation=tf.nn.elu)(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "output = tf.layers.Dense(units=1, activation=None)(hidden)\n",
    "# output = tf.layers.Dense(units=1, activation=None)(last_states)\n",
    "# output = tf.layers.Dense(units=4, activation=None)(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mae = tf.reduce_mean(tf.abs(output-y))\n",
    "mse = tf.reduce_mean(tf.pow(output-y, 2))\n",
    "\n",
    "rmae = tf.sqrt(tf.reduce_mean(tf.abs(output-y)))\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.pow(output-y, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(\n",
    "    learning_rate=0.0001\n",
    ")\n",
    "train_op = optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Слова в индексы эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "word2vec = gensim.models.Word2Vec.load('./../topic7-word2vec/word2vec32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# path = './../topic7-word2vec/normalized_train.csv' \n",
    "\n",
    "# with open('actual_train.csv','w') as f:\n",
    "#     with open(path, 'r') as f_norm_text:\n",
    "#         with open('./../dz4/big_train.csv', 'r') as f_rating:\n",
    "#             print(f_rating.readline())\n",
    "#             for norm_text_line, rating_line in zip(f_norm_text, f_rating):\n",
    "#                 data = rating_line.strip().split(',')\n",
    "#                 _id,context_id,label,text,likes,rating = data\n",
    "\n",
    "#                 if rating == 'n/a':\n",
    "#                     continue\n",
    "                    \n",
    "#                 f.write('%s,%s\\n' % (norm_text_line.split(',')[0].strip(), rating))\n",
    "                \n",
    "# # path = './../topic7-word2vec/normalized_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "word_dictionary = {w:i for (i,w) in enumerate(word2vec.wv.index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   84070 5214415 73895248 actual_train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc actual_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iter_data(batch_size=batch_size, is_train=True, is_val=True):\n",
    "    max_length = 50\n",
    "    batch_x, batch_y = [], []\n",
    "    if is_train:\n",
    "        path = 'actual_train.csv' \n",
    "    else:\n",
    "        path = 'actual_test.csv'\n",
    "        \n",
    "    with open(path, 'r') as f:\n",
    "        for _idx, line in enumerate(f):\n",
    "            \n",
    "            if is_train and is_val and _idx > 4200:\n",
    "                break\n",
    "                \n",
    "            if is_train and (not is_val) and _idx < 4200: #> 84070-4200:\n",
    "                continue\n",
    "                \n",
    "            if is_train:\n",
    "                text, label = line.strip().split(',')\n",
    "            else:\n",
    "                text, label = line.strip().split(',')\n",
    "            indexes = [\n",
    "                word_dictionary.get(word) \n",
    "                for word in text.split() \n",
    "                if word in word_dictionary\n",
    "            ]\n",
    "            if not indexes:\n",
    "                word_vectors = np.zeros( (max_length, 64), dtype=np.float32)\n",
    "            else:\n",
    "                word_vectors = word2vec.wv.syn0[indexes]\n",
    "\n",
    "            if word_vectors.shape[0]< max_length:\n",
    "                extra = np.array([\n",
    "                    [0 for i in range(64)]\n",
    "                    for j in range(max_length-word_vectors.shape[0])\n",
    "                ])\n",
    "                word_vectors = np.vstack(\n",
    "                    [\n",
    "                        word_vectors, extra\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            if word_vectors.shape[0]> max_length:\n",
    "                word_vectors = word_vectors[:max_length]\n",
    "                \n",
    "            batch_x.append(\n",
    "                word_vectors\n",
    "            )\n",
    "            \n",
    "            if is_train:\n",
    "#                 _label_vec = np.zeros(4)\n",
    "#                 _label_vec[int(label)] = 1\n",
    "                batch_y.append([int(label)])\n",
    "            \n",
    "            if len(batch_x) >=batch_size:\n",
    "                yield np.array(batch_x), np.array(batch_y)\n",
    "                batch_y, batch_x = [],[]\n",
    "                \n",
    "    if is_train==False:\n",
    "\n",
    "        while len(batch_x)<batch_size:\n",
    "            batch_x.append(\n",
    "                np.zeros( (max_length, 64), dtype=np.float32)\n",
    "            )\n",
    "            \n",
    "        yield np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_target(sess, filename):\n",
    "    Y_= []\n",
    "    for _tick, (_x,_y) in enumerate(iter_data(is_train=False)):\n",
    "\n",
    "        _output = sess.run(\n",
    "            [output],\n",
    "            feed_dict={\n",
    "                x: _x,\n",
    "            }\n",
    "        )\n",
    "        for probs in _output[0]:\n",
    "            Y_.append(probs)\n",
    "    Y_= np.array(Y_)\n",
    "    with open('%s.csv' % filename,'w') as sol:\n",
    "        with open('../dz4/rating_test_without_rating.csv', 'r') as f:\n",
    "            sol.write('_id,rating\\n')\n",
    "            f.readline()\n",
    "            for (line, label) in zip(f, Y_):\n",
    "                data = line.split(',')\n",
    "                sol.write('%s,%s\\n' % (data[0], label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100\n",
      "1.16(1.05), 2.15(1.82), 1.08(1.03), 1.47(1.35)\n",
      "0 200\n",
      "0.77(0.83), 1.05(1.22), 0.88(0.91), 1.03(1.10)\n",
      "0 300\n",
      "0.80(0.77), 1.20(1.05), 0.90(0.88), 1.10(1.02)\n",
      "0 400\n",
      "0.68(0.73), 0.81(0.97), 0.82(0.85), 0.90(0.98)\n",
      "0 500\n",
      "0.68(0.72), 0.79(0.94), 0.82(0.85), 0.89(0.96)\n",
      "0 600\n",
      "0.60(0.68), 0.69(0.91), 0.77(0.83), 0.83(0.95)\n",
      "1 100\n",
      "0.72(0.68), 0.91(0.87), 0.85(0.82), 0.95(0.93)\n",
      "1 200\n",
      "0.64(0.67), 0.68(0.86), 0.80(0.82), 0.83(0.92)\n",
      "1 300\n",
      "0.70(0.67), 0.93(0.85), 0.84(0.82), 0.96(0.92)\n",
      "1 400\n",
      "0.60(0.64), 0.73(0.83), 0.77(0.80), 0.85(0.91)\n",
      "1 500\n",
      "0.60(0.65), 0.66(0.82), 0.77(0.81), 0.81(0.90)\n",
      "1 600\n",
      "0.55(0.64), 0.60(0.82), 0.74(0.80), 0.77(0.90)\n",
      "2 100\n",
      "0.63(0.63), 0.75(0.80), 0.79(0.79), 0.86(0.89)\n",
      "2 200\n",
      "0.59(0.65), 0.61(0.80), 0.77(0.80), 0.78(0.89)\n",
      "2 300\n",
      "0.68(0.64), 0.88(0.79), 0.83(0.80), 0.94(0.89)\n",
      "2 400\n",
      "0.56(0.62), 0.65(0.78), 0.75(0.78), 0.81(0.88)\n",
      "2 500\n",
      "0.58(0.64), 0.63(0.78), 0.76(0.80), 0.79(0.88)\n",
      "2 600\n",
      "0.55(0.63), 0.56(0.78), 0.74(0.79), 0.75(0.88)\n",
      "3 100\n",
      "0.57(0.60), 0.65(0.77), 0.75(0.77), 0.81(0.87)\n",
      "3 200\n",
      "0.57(0.63), 0.57(0.77), 0.76(0.79), 0.75(0.87)\n",
      "3 300\n",
      "0.67(0.62), 0.83(0.76), 0.82(0.79), 0.91(0.87)\n",
      "3 400\n",
      "0.53(0.60), 0.61(0.76), 0.73(0.77), 0.78(0.87)\n",
      "3 500\n",
      "0.57(0.62), 0.61(0.75), 0.75(0.79), 0.78(0.86)\n",
      "3 600\n",
      "0.53(0.62), 0.54(0.76), 0.73(0.79), 0.73(0.87)\n",
      "4 100\n",
      "0.53(0.58), 0.59(0.75), 0.73(0.76), 0.77(0.86)\n",
      "4 200\n",
      "0.55(0.62), 0.54(0.74), 0.74(0.79), 0.73(0.86)\n",
      "4 300\n",
      "0.65(0.61), 0.79(0.74), 0.80(0.78), 0.89(0.86)\n",
      "4 400\n",
      "0.51(0.59), 0.58(0.74), 0.72(0.77), 0.76(0.86)\n",
      "4 500\n",
      "0.55(0.61), 0.58(0.74), 0.74(0.78), 0.76(0.86)\n",
      "4 600\n",
      "0.51(0.61), 0.52(0.74), 0.72(0.78), 0.72(0.86)\n",
      "5 100\n",
      "0.51(0.57), 0.53(0.73), 0.71(0.76), 0.73(0.85)\n",
      "5 200\n",
      "0.54(0.61), 0.51(0.73), 0.73(0.78), 0.71(0.85)\n",
      "5 300\n",
      "0.63(0.60), 0.75(0.73), 0.79(0.77), 0.87(0.85)\n",
      "5 400\n",
      "0.50(0.58), 0.56(0.73), 0.71(0.76), 0.75(0.85)\n",
      "5 500\n",
      "0.54(0.61), 0.55(0.73), 0.74(0.78), 0.74(0.85)\n",
      "5 600\n",
      "0.49(0.60), 0.50(0.73), 0.70(0.77), 0.70(0.85)\n",
      "6 100\n",
      "0.48(0.57), 0.48(0.72), 0.70(0.75), 0.69(0.85)\n",
      "6 200\n",
      "0.52(0.61), 0.48(0.72), 0.72(0.78), 0.69(0.85)\n",
      "6 300\n",
      "0.61(0.59), 0.72(0.72), 0.78(0.77), 0.85(0.85)\n",
      "6 400\n",
      "0.49(0.58), 0.55(0.72), 0.70(0.76), 0.74(0.85)\n",
      "6 500\n",
      "0.53(0.60), 0.52(0.72), 0.73(0.78), 0.72(0.85)\n",
      "6 600\n",
      "0.48(0.60), 0.48(0.73), 0.69(0.77), 0.69(0.85)\n",
      "7 100\n",
      "0.46(0.56), 0.44(0.72), 0.68(0.75), 0.66(0.84)\n"
     ]
    }
   ],
   "source": [
    "min_mse = 2\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     saver.restore(sess, save_path='./rating_rnn.model')\n",
    "    try:\n",
    "        for epoch in range(0,20):\n",
    "            for _tick, (_x,_y) in enumerate(iter_data(is_train=True,is_val=False)):\n",
    "\n",
    "                _, _mae, _mse, _rmae, _rmse = sess.run(\n",
    "                    [train_op, mae, mse, rmae, rmse ],\n",
    "                    feed_dict={\n",
    "                        x: _x,\n",
    "                        y: _y\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if _tick and not _tick % 100:\n",
    "                    \n",
    "                    loss_ = []\n",
    "                    for (_x,_y) in iter_data(is_train=True,is_val=True):\n",
    "                        loss_list = sess.run(\n",
    "                            [mae, mse, rmae, rmse],\n",
    "                            feed_dict={\n",
    "                                x: _x,\n",
    "                                y: _y,\n",
    "                            }\n",
    "                        )\n",
    "                        loss_.append(loss_list)\n",
    "                    loss_ = np.array(loss_)\n",
    "                    loss_ = loss_.mean(axis=0)\n",
    "                    print(epoch,_tick)\n",
    "                    print(\n",
    "                        '%3.2f(%3.2f), %3.2f(%3.2f), %3.2f(%3.2f), %3.2f(%3.2f)' % (\n",
    "                            _mae,loss_[0],\n",
    "                            _mse,loss_[1],\n",
    "                            _rmae,loss_[2],\n",
    "                            _rmse,loss_[3]\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "                    if min_mse>loss_[1]:\n",
    "                        if epoch< 1: continue\n",
    "                        min_mse = loss_[1]\n",
    "                        eval_target(sess, 'rating_2xbi-lstm_%s.csv' % min_mse)\n",
    "                            \n",
    "                    saver.save(sess=sess, save_path='./rating_rnn.model')\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            saver.save(sess=sess, save_path='./rating_rnn.model')\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        saver.save(sess=sess, save_path='./rating_rnn.model')\n",
    "        raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./rating_rnn.model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, save_path='./rating_rnn.model')\n",
    "    \n",
    "    eval_target(sess, 'rating_rnn_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y_= np.array(Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83328, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('rating_rnn_.csv','w') as sol:\n",
    "    with open('../dz4/rating_test_without_rating.csv', 'r') as f:\n",
    "        sol.write('_id,rating\\n')\n",
    "        f.readline()\n",
    "        for (line, label) in zip(f, Y_):\n",
    "            data = line.split(',')\n",
    "            sol.write('%s,%s\\n' % (data[0], label[0]))\n",
    "#             yield preprocessing(line.strip().split(',')[1].lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   83221 7245744 84404527 ../dz4/rating_test_without_rating.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc ../dz4/rating_test_without_rating.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
