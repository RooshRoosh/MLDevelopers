{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\n",
    "    shape=[batch_size, 40, 64],\n",
    "    dtype=tf.float32\n",
    ")\n",
    "y = tf.placeholder(\n",
    "    shape=[batch_size, 4],\n",
    "    dtype=tf.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(\n",
    "    num_units=128, \n",
    "    activation=tf.nn.tanh\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(128, 40, 64) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outputs, last_states = tf.nn.dynamic_rnn(\n",
    "    cell=rnn_cell,\n",
    "    inputs=x,\n",
    "    dtype=tf.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose:0' shape=(128, 40, 128) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/while/Exit_2:0' shape=(128, 128) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fw_lstm_cell = tf.contrib.rnn.LSTMCell(\n",
    "#     num_units=128, \n",
    "# )\n",
    "# bw_lstm_cell = tf.contrib.rnn.LSTMCell(\n",
    "#     num_units=128, \n",
    "# )\n",
    "# outputs, final_fw, final_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
    "#     [fw_lstm_cell],\n",
    "#     [bw_lstm_cell],\n",
    "#     x,\n",
    "#     dtype=tf.float32\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# final_fw =  tf.concat( [final_fw[0][0],final_fw[0][1]],axis=1)\n",
    "# final_bw =  tf.concat( [final_bw[0][0],final_bw[0][1]],axis=1)\n",
    "# final = tf.concat( [final_fw, final_bw], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# last_states = tf.concat( [last_states[0], last_states[1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = tf.layers.Dense(units=4, activation=None)(last_states)\n",
    "# output = tf.layers.Dense(units=4, activation=None)(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Softmax:0\", shape=(128, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "softmax = tf.nn.softmax(output)\n",
    "print(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=output,\n",
    "    labels=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(out_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(\n",
    "    learning_rate=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Слова в индексы эмбеддинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "word2vec = gensim.models.Word2Vec.load('./../topic7-word2vec/word2vec32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word2vec.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_dictionary = {w:i for (i,w) in enumerate(word2vec.wv.index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iter_data(batch_size=batch_size, is_train=True):\n",
    "    max_length = 40\n",
    "    batch_x, batch_y = [], []\n",
    "    if is_train:\n",
    "        path = './../topic7-word2vec/normalized_train.csv' \n",
    "    else:\n",
    "        path = './../topic7-word2vec/normalized_test.csv'\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if is_train:\n",
    "                text, label = line.strip().split(',')\n",
    "            else:\n",
    "                text = line.strip()\n",
    "            indexes = [\n",
    "                word_dictionary.get(word) \n",
    "                for word in text.split() \n",
    "                if word in word_dictionary\n",
    "            ]\n",
    "            if not indexes:\n",
    "                word_vectors = np.zeros( (max_length, 64), dtype=np.float32)\n",
    "            else:\n",
    "                word_vectors = word2vec.wv.syn0[indexes]\n",
    "\n",
    "            if word_vectors.shape[0]< max_length:\n",
    "                extra = np.array([\n",
    "                    [0 for i in range(64)]\n",
    "                    for j in range(max_length-word_vectors.shape[0])\n",
    "                ])\n",
    "                word_vectors = np.vstack(\n",
    "                    [\n",
    "                        word_vectors, extra\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            if word_vectors.shape[0]> max_length:\n",
    "                word_vectors = word_vectors[:max_length]\n",
    "                \n",
    "            batch_x.append(\n",
    "                word_vectors\n",
    "            )\n",
    "            \n",
    "            if is_train:\n",
    "                _label_vec = np.zeros(4)\n",
    "                _label_vec[int(label)] = 1\n",
    "                batch_y.append(_label_vec)\n",
    "            \n",
    "            if len(batch_x) >=batch_size:\n",
    "                yield np.array(batch_x), np.array(batch_y)\n",
    "                batch_y, batch_x = [],[]\n",
    "                \n",
    "    if is_train==False:\n",
    "\n",
    "        while len(batch_x)<batch_size:\n",
    "            batch_x.append(\n",
    "                np.zeros( (max_length, 64), dtype=np.float32)\n",
    "            )\n",
    "            \n",
    "        yield np.array(batch_x), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.45885\n",
      "0 100 1.039\n",
      "0 200 0.891637\n",
      "0 300 0.717351\n",
      "0 400 0.769657\n",
      "0 500 0.762388\n",
      "0 600 0.73753\n",
      "0 700 0.58627\n",
      "0 800 0.768123\n",
      "0 900 0.531139\n",
      "0 1000 0.639696\n",
      "0 1100 0.550685\n",
      "0 1200 0.557653\n",
      "1 0 0.713187\n",
      "1 100 0.66587\n",
      "1 200 0.517392\n",
      "1 300 0.485721\n",
      "1 400 0.479181\n",
      "1 500 0.41173\n",
      "1 600 0.412269\n",
      "1 700 0.286862\n",
      "1 800 0.329401\n",
      "1 900 0.260743\n",
      "1 1000 0.369075\n",
      "1 1100 0.256139\n",
      "1 1200 0.26721\n",
      "2 0 0.359015\n",
      "2 100 0.414654\n",
      "2 200 0.211947\n",
      "2 300 0.302868\n",
      "2 400 0.322763\n",
      "2 500 0.276405\n",
      "2 600 0.344258\n",
      "2 700 0.236742\n",
      "2 800 0.225065\n",
      "2 900 0.24767\n",
      "2 1000 0.297133\n",
      "2 1100 0.216627\n",
      "2 1200 0.278457\n",
      "3 0 0.272494\n",
      "3 100 0.352289\n",
      "3 200 0.190759\n",
      "3 300 0.289807\n",
      "3 400 0.284497\n",
      "3 500 0.258116\n",
      "3 600 0.345632\n",
      "3 700 0.222088\n",
      "3 800 0.20313\n",
      "3 900 0.230294\n",
      "3 1000 0.258569\n",
      "3 1100 0.188342\n",
      "3 1200 0.279722\n",
      "4 0 0.253748\n",
      "4 100 0.334386\n",
      "4 200 0.189797\n",
      "4 300 0.283581\n",
      "4 400 0.266978\n",
      "4 500 0.239844\n",
      "4 600 0.336768\n",
      "4 700 0.203605\n",
      "4 800 0.189082\n",
      "4 900 0.235082\n",
      "4 1000 0.22834\n",
      "4 1100 0.175602\n",
      "4 1200 0.276545\n",
      "5 0 0.235321\n",
      "5 100 0.32741\n",
      "5 200 0.185225\n",
      "5 300 0.281019\n",
      "5 400 0.263485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e3154674de54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./rnn.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/talipov/MyProjects/projectX/acosta_env/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_meta_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_graph_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e3154674de54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./rnn.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(10):\n",
    "            for _tick, (_x,_y) in enumerate(iter_data()):\n",
    "\n",
    "                _, _loss,_softmax = sess.run(\n",
    "                    [train_op, loss, softmax],\n",
    "                    feed_dict={\n",
    "                        x: _x,\n",
    "                        y: _y\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if not _tick % 100:\n",
    "                    print(epoch,_tick, _loss)\n",
    "\n",
    "                    saver.save(sess=sess, save_path='./rnn.model')\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        saver.save(sess=sess, save_path='./rnn.model')\n",
    "        raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./rnn.model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, save_path='./rnn.model')\n",
    "    \n",
    "    Y_probs = []\n",
    "    \n",
    "    for _tick, (_x,_y) in enumerate(iter_data(is_train=False)):\n",
    "\n",
    "        _softmax = sess.run(\n",
    "            [softmax],\n",
    "            feed_dict={\n",
    "                x: _x,\n",
    "            }\n",
    "        )\n",
    "        for probs in _softmax[0]:\n",
    "            Y_probs.append(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_probs = np.array(Y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156672, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('rnn_.csv','w') as sol:\n",
    "    with open('../dz4/source_task_test_without_labels.csv', 'r') as f:\n",
    "        sol.write('_id,label\\n')\n",
    "        f.readline()\n",
    "        for (line, label) in zip(f, Y_probs):\n",
    "            data = line.split(',')\n",
    "            sol.write('%s,%s\\n' % (data[0], label.argmax()))\n",
    "#             yield preprocessing(line.strip().split(',')[1].lower()).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
